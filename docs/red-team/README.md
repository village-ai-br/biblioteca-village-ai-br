# üî¥ Red Team & Offensive Security em IA

Recursos espec√≠ficos para red teaming, testes de penetra√ß√£o e seguran√ßa ofensiva em sistemas de IA.

## üéì Cursos Especializados

### **Web LLM Attacks**
- **Plataforma**: PortSwigger Web Security Academy
- **Descri√ß√£o**: Curso sobre ataques espec√≠ficos a Large Language Models
- **Link**: [PortSwigger](https://portswigger.net/web-security/llm-attacks)
- **N√≠vel**: Intermedi√°rio/Avan√ßado
- **Idioma**: Ingl√™s

## üìö Leituras Especializadas

### **Artigos Acad√™micos: AI Security Attacks**
- **Plataforma**: arXiv
- **Descri√ß√£o**: Cole√ß√£o de artigos acad√™micos sobre ataques de seguran√ßa em IA
- **Link**: [arXiv](https://arxiv.org/search/?query=ai+security+attacks)
- **Idioma**: Ingl√™s

### **Blog Embrace The Red**
- **Descri√ß√£o**: Blog especializado em red teaming e seguran√ßa ofensiva
- **Link**: [embracethered.com](https://embracethered.com/blog/)
- **Idioma**: Ingl√™s

### **Research Initiative: AI Red Teaming & Evaluation**
- **Organiza√ß√£o**: OWASP
- **Descri√ß√£o**: Iniciativa de pesquisa sobre red teaming em IA
- **Link**: [OWASP](https://genai.owasp.org/2024/09/12/research-initiative-ai-red-teaming-evaluation/)
- **Idioma**: Ingl√™s

### **Why Red Teams Play a Central Role in Helping Organizations Secure AI Systems**
- **Organiza√ß√£o**: Google
- **Descri√ß√£o**: Whitepaper sobre o papel dos red teams na seguran√ßa de sistemas de IA
- **Link**: [Google](https://services.google.com/fh/files/blogs/google_ai_red_team_digital_final.pdf)
- **Tipo**: PDF
- **Idioma**: Ingl√™s

### **Google's AI Red Team: the ethical hackers making AI safer**
- **Organiza√ß√£o**: Google
- **Descri√ß√£o**: Artigo sobre o time de red team de IA do Google
- **Link**: [Google Blog](https://blog.google/technology/safety-security/googles-ai-red-team-the-ethical-hackers-making-ai-safer/)
- **Idioma**: Ingl√™s

### **Microsoft AI Red Team**
- **Organiza√ß√£o**: Microsoft
- **Descri√ß√£o**: Documenta√ß√£o oficial sobre red teaming em IA da Microsoft
- **Link**: [Microsoft Learn](https://learn.microsoft.com/en-us/security/ai-red-team/)
- **Idioma**: Ingl√™s

## üèÜ CTF & Desafios Pr√°ticos

### **Lakera Gandalf**
- **Tipo**: CTF/Desafio
- **Descri√ß√£o**: Desafio de prompt injection e manipula√ß√£o de LLMs
- **Link**: [gandalf.lakera.ai](https://gandalf.lakera.ai/trial-summarization-novice)
- **N√≠vel**: Todos os n√≠veis
- **Idioma**: Ingl√™s

## ü§ù Comunidades

### **AI Village**
- **Tipo**: Comunidade/Organiza√ß√£o
- **Descri√ß√£o**: Comunidade focada em seguran√ßa de IA e machine learning
- **Link**: [aivillage.org](https://aivillage.org/)
- **Idioma**: Ingl√™s

---

## Recursos Adicionais

### Metodologias e Frameworks
- Consulte tamb√©m a se√ß√£o de [Frameworks](../frameworks/README.md) para metodologias estruturadas de red teaming

### Ferramentas
- Veja a se√ß√£o de [Ferramentas](../ferramentas/README.md) para tools espec√≠ficas de red teaming

## Como Contribuir

Para adicionar novos recursos de red team:
1. Certifique-se de que o conte√∫do √© √©tico e educacional
2. Inclua informa√ß√µes sobre n√≠vel de dificuldade
3. Especifique se √© pr√°tico (hands-on) ou te√≥rico
4. Adicione tags relevantes (#prompt-injection, #llm-security, etc.)

[‚Üê Voltar ao README principal](../../README.md)
